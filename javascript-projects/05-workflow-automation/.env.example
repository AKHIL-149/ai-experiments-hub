# Node.js Server
PORT=3000
PYTHON_PATH=python3
PYTHON_TIMEOUT=300000

# Python/LLM Configuration
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# Storage Paths
WORKFLOWS_DIR=./workflows
EXECUTIONS_DIR=./data/executions
ARTIFACTS_DIR=./data/artifacts

# Execution Settings
MAX_CONCURRENT_EXECUTIONS=5
EXECUTION_TIMEOUT=600000

# Logging
LOG_LEVEL=info
