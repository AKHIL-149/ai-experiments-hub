# Server Configuration
PORT=3000
NODE_ENV=development

# Phase 5: Service Mode
# Options: cloud, local, hybrid
# cloud = OpenAI only (requires OPENAI_API_KEY)
# local = Local models only (requires whisper.cpp and local TTS)
# hybrid = Prefer local with cloud fallback (best of both worlds)
SERVICE_MODE=local
FALLBACK_TO_CLOUD=true

# OpenAI API Configuration (for cloud/hybrid mode)
OPENAI_API_KEY=your_openai_api_key_here
WHISPER_MODEL=whisper-1
TTS_MODEL=tts-1
TTS_VOICE=alloy

# Phase 5: Local Whisper Configuration (for local/hybrid mode)
# Download models from: https://huggingface.co/ggerganov/whisper.cpp
WHISPER_CPP_PATH=./whisper.cpp/build/bin/whisper-cli
WHISPER_MODEL_PATH=./whisper.cpp/models/ggml-base.en.bin
WHISPER_THREADS=4

# Phase 5: Local TTS Configuration (for local/hybrid mode)
# Supported engines: espeak, piper, festival
# espeak: apt-get install espeak (Linux) or brew install espeak (Mac)
# piper: Download from https://github.com/rhasspy/piper
# festival: apt-get install festival
TTS_ENGINE=espeak
TTS_SPEED=175

# Audio Settings
MAX_AUDIO_SIZE_MB=25
AUDIO_TEMP_DIR=./data/audio-cache
CLEANUP_INTERVAL_MS=3600000

# Conversation Settings
CONVERSATIONS_DIR=./data/conversations
MAX_CONVERSATION_LENGTH=50
CONTEXT_WINDOW=10

# Rate Limiting
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=60

# CORS
ALLOWED_ORIGINS=http://localhost:3000

# Logging
LOG_LEVEL=info
