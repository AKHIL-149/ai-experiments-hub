# Voice Assistant

AI-powered voice assistant with speech-to-text and text-to-speech capabilities using OpenAI's Whisper and TTS APIs.

## Features

### Phase 1: Core MVP âœ…
- ğŸ¤ **Voice Recording** - Browser-based audio capture with push-to-talk
- ğŸ—£ï¸ **Speech-to-Text** - OpenAI Whisper API for accurate transcription
- ğŸ”Š **Text-to-Speech** - Natural voice responses with multiple voice options
- ğŸ’¬ **Conversation Interface** - Chat-style UI showing dialogue history
- âš¡ **Real-time Processing** - Fast audio transcription and synthesis
- ğŸ¨ **Modern UI** - Clean, responsive interface with visual feedback

### Phase 2: Voice Commands âœ… (Current)
- ğŸ¯ **Pattern Matching** - Intelligent command recognition with fuzzy matching
- ğŸ¤– **8 Built-in Commands** - Time, date, jokes, calculations, timers, weather, help, greetings
- ğŸ“ **Parameterized Commands** - Extract values from voice input (e.g., "timer for 5 minutes")
- ğŸ”„ **AI Fallback** - Seamless fallback to conversational AI for unrecognized commands
- ğŸ“‹ **Extensible Registry** - Easy-to-add custom commands via JSON configuration
- ğŸ­ **Natural Language** - Understands variations and natural phrasing

### Upcoming Features
- **Phase 3**: Conversation context and memory
- **Phase 4**: Real-time streaming and audio visualization
- **Phase 5**: Local model integration (Whisper.cpp)

## Quick Start

### Prerequisites
- Node.js 16+ and npm
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))
- Modern web browser (Chrome, Firefox, Safari, or Edge)
- Microphone access

### Installation

1. **Install dependencies**
```bash
npm install
```

2. **Configure environment**
```bash
cp .env.example .env
```

Edit `.env` and add your OpenAI API key:
```bash
OPENAI_API_KEY=your_api_key_here
```

3. **Start the server**
```bash
npm start
```

For development with auto-reload:
```bash
npm run dev
```

4. **Open in browser**
```
http://localhost:3000
```

## Usage

1. **Allow Microphone Access** - Your browser will request permission on first use
2. **Push to Talk** - Click and hold the record button while speaking
3. **Release to Send** - Release the button to process your audio
4. **Listen to Response** - The assistant will respond with both text and voice
5. **Continue Conversation** - Speak again to continue the dialogue

### Settings
Click the âš™ï¸ icon to customize:
- **Voice**: Choose from 6 different voices (alloy, echo, fable, onyx, nova, shimmer)
- **Speed**: Adjust playback speed (0.75x - 1.5x)

### Voice Commands

The assistant recognizes these built-in commands (speak naturally - variations are understood):

**Utility Commands:**
- ğŸ• "What time is it?" - Get current time
- ğŸ“… "What's the date?" - Get current date
- ğŸ§® "Calculate 25 times 4" - Perform math calculations
- â²ï¸ "Set a timer for 5 minutes" - Start countdown timer

**Information:**
- ğŸŒ¤ï¸ "What's the weather?" - Get weather info (placeholder - API integration needed)

**Entertainment:**
- ğŸ˜„ "Tell me a joke" - Random joke

**System:**
- â“ "Help" or "What can you do?" - List available commands
- ğŸ‘‹ "Hello" or "Hi" - Greeting response

**Natural Language Examples:**
- "What is 50 plus 32?"
- "Timer for 10 minutes"
- "Calculate 100 divided by 4"
- "Good morning"

If a command isn't recognized, the assistant falls back to conversational AI mode.

## Project Structure

```
08-voice-assistant/
â”œâ”€â”€ server.js                    # Express server (main entry)
â”œâ”€â”€ package.json                 # Dependencies
â”œâ”€â”€ .env.example                 # Configuration template
â”œâ”€â”€ README.md                    # Documentation
â”œâ”€â”€ public/                      # Frontend assets
â”‚   â”œâ”€â”€ index.html              # UI
â”‚   â”œâ”€â”€ styles.css              # Styling
â”‚   â””â”€â”€ app.js                  # Frontend logic
â”œâ”€â”€ src/                        # Backend modules
â”‚   â”œâ”€â”€ OpenAIService.js        # OpenAI API wrapper
â”‚   â”œâ”€â”€ AudioProcessor.js       # Audio coordination
â”‚   â””â”€â”€ VoiceCommandHandler.js  # Command recognition & execution
â”œâ”€â”€ commands/                   # Voice commands
â”‚   â””â”€â”€ commands.json           # Command registry & patterns
â””â”€â”€ data/                       # Persistent storage
    â”œâ”€â”€ conversations/          # Conversation history (Phase 3)
    â””â”€â”€ audio-cache/            # Temporary audio files
```

## API Endpoints

### Health Check
```
GET /api/health
```
Returns server status and OpenAI connection status.

### Transcribe Audio
```
POST /api/transcribe
Body: FormData with 'audio' field (audio/webm)
Returns: { transcript, duration, confidence }
```

### Synthesize Speech
```
POST /api/synthesize
Body: { text, voice?, speed? }
Returns: Audio stream (audio/mpeg)
```

### Process Voice Command
```
POST /api/command
Body: { transcript }
Returns: { understood, commandRecognized, command, response, audio, audioFormat }
```
Processes transcribed text through command handler or AI fallback.

### Get Available Voices
```
GET /api/voices
Returns: { voices: [...] }
```

### Get Available Commands
```
GET /api/commands
Returns: { commands: [{ id, name, description, category, examples }] }
```
Lists all registered voice commands with examples.

## Configuration

Environment variables (`.env`):

```bash
# Server
PORT=3000
NODE_ENV=development

# OpenAI
OPENAI_API_KEY=your_key_here
WHISPER_MODEL=whisper-1
TTS_MODEL=tts-1
TTS_VOICE=alloy

# Audio
MAX_AUDIO_SIZE_MB=25
AUDIO_TEMP_DIR=./data/audio-cache
CLEANUP_INTERVAL_MS=3600000

# CORS
ALLOWED_ORIGINS=http://localhost:3000
```

## Browser Compatibility

- âœ… Chrome 60+
- âœ… Firefox 55+
- âœ… Safari 14+
- âœ… Edge 79+

**Requirements**:
- Web Audio API support
- MediaRecorder API support
- HTTPS (for production deployment)

## Technical Details

### Audio Processing
- **Input Format**: WebM (captured via MediaRecorder API)
- **Sample Rate**: 16kHz (optimized for speech)
- **Transcription**: OpenAI Whisper API
- **Output Format**: MP3 (from TTS API)

### Architecture
- **Backend**: Node.js + Express.js
- **Frontend**: Vanilla JavaScript (no frameworks)
- **Audio Handling**: Web Audio API + MediaRecorder
- **API Integration**: OpenAI Node.js SDK

## Troubleshooting

### Microphone Not Working
- Ensure microphone permission is granted in browser settings
- Check that your microphone is not being used by another application
- Try using HTTPS (required for production)

### API Errors
- Verify your OpenAI API key is correct
- Check your API key has sufficient credits
- Ensure you have access to Whisper and TTS models

### Audio Quality Issues
- Minimize background noise
- Speak clearly at normal pace
- Ensure stable internet connection
- Try different voices in settings

## Development

### Phase 1 Complete âœ…
- [x] Project structure
- [x] OpenAI service integration
- [x] Audio recording and playback
- [x] Basic transcription and TTS
- [x] Web interface
- [x] Settings management

### Phase 2 Complete âœ…
- [x] Command pattern matching with fuzzy logic
- [x] Intent recognition and parameter extraction
- [x] 8 custom command handlers
- [x] Command registry system (JSON)
- [x] AI fallback for unrecognized commands
- [x] GET /api/commands endpoint

### Phase 3: Conversation Memory
- [ ] Context tracking
- [ ] Multi-turn dialogue
- [ ] History persistence
- [ ] Session management

## Security Notes

- API keys are server-side only (never exposed to client)
- CORS configured for specific origins
- Audio file size limits enforced
- Temporary files automatically cleaned up
- Rate limiting on API endpoints

## Contributing

This is part of the [AI Experiments Hub](https://github.com/yourusername/ai-experiments-hub) repository.

## License

MIT

## Links

- [OpenAI Whisper API Documentation](https://platform.openai.com/docs/guides/speech-to-text)
- [OpenAI TTS API Documentation](https://platform.openai.com/docs/guides/text-to-speech)
- [MediaRecorder API](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)
- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)

---

**Project 8** of AI Experiments Hub | Built with OpenAI APIs
