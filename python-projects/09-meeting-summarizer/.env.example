# Server Configuration
PORT=8000
HOST=0.0.0.0

# Transcription Backend
TRANSCRIPTION_BACKEND=openai          # openai, whisper-cpp
OPENAI_API_KEY=your_openai_key_here
WHISPER_MODEL=whisper-1               # whisper-1, whisper-large-v3

# Local Whisper.cpp (optional - for offline transcription)
WHISPER_CPP_PATH=./whisper.cpp/main
WHISPER_CPP_MODEL=./models/ggml-medium.bin

# Summarization Backend
LLM_PROVIDER=anthropic                # openai, anthropic, ollama
LLM_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_API_KEY=your_anthropic_key_here

# OpenAI (alternative for summarization)
# OPENAI_API_KEY=your_openai_key_here
# LLM_MODEL=gpt-4o-mini

# Ollama (local LLM option - free, offline)
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Audio Processing
MAX_AUDIO_SIZE_MB=500
CHUNK_DURATION_MINUTES=10
OVERLAP_SECONDS=5
SUPPORTED_FORMATS=mp3,wav,webm,m4a,ogg,flac

# Caching
CACHE_DIR=./data/cache
TRANSCRIPTION_CACHE_TTL_DAYS=30       # Keep transcripts longer
SUMMARY_CACHE_TTL_DAYS=7
ENABLE_CACHE=true

# Output
OUTPUT_DIR=./data/output
DEFAULT_OUTPUT_FORMAT=markdown        # markdown, json, html, txt

# Processing
PARALLEL_CHUNKS=true
MAX_WORKERS=4

# Cost Tracking
TRACK_COSTS=true
WHISPER_COST_PER_MINUTE=0.006
GPT4_COST_PER_1K_TOKENS=0.03
CLAUDE_COST_PER_1K_TOKENS=0.003
