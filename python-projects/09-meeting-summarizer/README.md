# Meeting Summarizer - Phases 1-5 Complete

AI-powered meeting transcription, summarization, and action item extraction with batch processing, web interface, database persistence, video support, and speaker diarization. Transform audio and video recordings into comprehensive meeting reports with intelligent caching for cost optimization.

## Features

### Phase 1: Core Foundation âœ…
- âœ… Multi-format audio support (MP3, WAV, WebM, M4A, OGG, FLAC)
- âœ… Cloud transcription via OpenAI Whisper API
- âœ… Local transcription via Whisper.cpp (offline mode)
- âœ… Intelligent chunking for long meetings (2+ hours)
- âœ… Two-level caching system (70%+ cost savings)
- âœ… Cost estimation and tracking
- âœ… CLI interface with progress tracking

### Phase 2: AI Summarization & Action Extraction âœ…
- âœ… AI-powered summarization (OpenAI, Anthropic, Ollama)
- âœ… Map-reduce strategy for long transcripts
- âœ… Multi-level summaries (brief, standard, detailed)
- âœ… Automatic action item extraction
- âœ… Decision tracking
- âœ… Key topic identification
- âœ… Multiple output formats (Markdown, JSON, HTML, TXT)

### Phase 3: Batch Processing & Advanced Features âœ…
- âœ… Batch processing for multiple files
- âœ… Parallel file processing with configurable workers
- âœ… Progress tracking with real-time updates
- âœ… Cancellation support for long-running jobs
- âœ… Resume capability for interrupted processing
- âœ… Batch report generation with statistics
- âœ… Automatic audio file discovery (recursive search)

### Phase 4: Web Interface & Real-time Progress âœ…
- âœ… FastAPI web server with REST API
- âœ… Modern web UI for file uploads
- âœ… Real-time progress tracking via WebSocket
- âœ… Drag-and-drop file upload
- âœ… Visual progress indicators with stage tracking
- âœ… Download analysis reports from browser
- âœ… Job management (list, view, delete)
- âœ… Responsive design for mobile and desktop

### Phase 5: Advanced Features âœ…
- âœ… Database persistence with SQLAlchemy (SQLite/PostgreSQL)
- âœ… Video file support (MP4, AVI, MOV, MKV, WebM, FLV, WMV)
- âœ… Speaker diarization (identify individual speakers)
- âœ… Custom summary templates (executive, detailed, brief, technical)
- âœ… Job history and statistics tracking
- âœ… Automatic audio extraction from video files
- âœ… Template-based report generation (Jinja2)

## Quick Start

### 1. Installation

```bash
cd python-projects/09-meeting-summarizer

# Install dependencies
pip install -r requirements.txt

# Install ffmpeg (required for audio processing)
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

### 2. Configuration

Create a `.env` file from the example:

```bash
cp .env.example .env
```

Edit `.env` and add your API keys:

```bash
# Transcription Backend
TRANSCRIPTION_BACKEND=openai
OPENAI_API_KEY=your_openai_key_here

# Summarization Backend (Phase 2)
LLM_PROVIDER=openai               # or anthropic, ollama
LLM_MODEL=gpt-4o-mini
# ANTHROPIC_API_KEY=your_key_here # if using Anthropic

# Or use local models (free, offline)
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=llama3.2
```

### 3. Basic Usage

**Analyze a meeting (Phase 2 - Full Pipeline):**

```bash
python summarize.py analyze meeting.mp3
# Output: Transcript + Summary + Action Items + Topics
```

**Transcribe only (Phase 1):**

```bash
python summarize.py transcribe meeting.mp3
```

**Analyze with custom summary level:**

```bash
python summarize.py analyze meeting.mp3 --level brief
# Options: brief, standard, detailed
```

**Analyze with specific output format:**

```bash
python summarize.py analyze meeting.mp3 --format json
# Options: markdown (default), json, html, txt
```

**Analyze without action extraction:**

```bash
python summarize.py analyze meeting.mp3 --no-actions
```

**Batch process multiple files (Phase 3):**

```bash
python summarize.py batch ./meetings --recursive
# Process all audio files in directory and subdirectories
```

**Batch with custom settings:**

```bash
python summarize.py batch ./meetings --workers 8 --level brief --save-individual
# Use 8 parallel workers, brief summaries, save individual reports
```

**Web interface (Phase 4):**

```bash
python server.py
# Server runs on http://localhost:8000
# Open in browser and upload files via UI
```

**Transcribe with language specification:**

```bash
python summarize.py transcribe meeting.mp3 --language en
```

**Force chunked processing for long audio:**

```bash
python summarize.py transcribe long_meeting.mp3 --chunked
```

**Validate audio file:**

```bash
python summarize.py validate meeting.mp3
```

**View cache statistics:**

```bash
python summarize.py cache-stats --cleanup
```

## Architecture

### Core Components

```
src/core/
â”œâ”€â”€ audio_processor.py       # Audio loading, validation, chunking
â”œâ”€â”€ transcription_service.py # Multi-backend transcription
â””â”€â”€ cache_manager.py         # Two-level caching system
```

### Audio Processor

Handles all audio file operations:

- **Format Support**: MP3, WAV, WebM, M4A, OGG, FLAC
- **Validation**: File size, format, duration checks
- **Metadata Extraction**: Duration, bitrate, sample rate, channels
- **Chunking**: Split long audio into 10-minute segments with 5s overlap
- **File Hashing**: SHA256 for cache key generation

### Transcription Service

Unified interface for multiple backends:

**OpenAI Whisper API** (Primary):
- Cloud-based, highest accuracy
- Cost: $0.006 per minute
- Model: `whisper-1`
- Supports 50+ languages

**Whisper.cpp** (Local):
- Offline operation, zero cost
- Requires binary and model download
- Good for privacy-sensitive meetings

### Cache Manager

Two-level caching for cost optimization:

**Level 1 - Transcription Cache**:
- Cache key: SHA256 hash of audio file
- TTL: 30 days (configurable)
- Saves most expensive operation

**Level 2 - Summary Cache** (Phase 2):
- Cache key: SHA256 hash of transcript + model name
- TTL: 7 days (configurable)
- Allows different models on same transcript

**Cost Tracking**:
```python
# Automatic cost estimation
{
  "estimated_cost_saved_usd": 12.45,
  "transcription_hit_rate": 72.5,
  "summary_hit_rate": 68.0
}
```

## Configuration Options

### Transcription Backend

```bash
# OpenAI Whisper API (default)
TRANSCRIPTION_BACKEND=openai
OPENAI_API_KEY=your_key_here
WHISPER_MODEL=whisper-1

# Local Whisper.cpp (offline)
TRANSCRIPTION_BACKEND=whisper-cpp
WHISPER_CPP_PATH=./whisper.cpp/main
WHISPER_CPP_MODEL=./models/ggml-medium.bin
```

### Audio Processing

```bash
# Maximum audio file size (MB)
MAX_AUDIO_SIZE_MB=500

# Chunk duration for long audio (minutes)
CHUNK_DURATION_MINUTES=10

# Overlap between chunks (seconds)
OVERLAP_SECONDS=5
```

### Caching

```bash
# Cache directory
CACHE_DIR=./data/cache

# Time-to-live (days)
TRANSCRIPTION_CACHE_TTL_DAYS=30
SUMMARY_CACHE_TTL_DAYS=7

# Enable/disable caching
ENABLE_CACHE=true
```

### Output

```bash
# Output directory
OUTPUT_DIR=./data/output

# Default format (markdown, json, html, txt)
DEFAULT_OUTPUT_FORMAT=markdown
```

## Examples

### Example 1: Quick Transcription

```bash
$ python summarize.py transcribe meeting.mp3

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Meeting Summarizer - Phase 1        â•‘
â•‘   Audio Transcription with Caching    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â„¹ Initializing services...
â„¹ Validating audio file: meeting.mp3
â„¹ Duration: 180.5s (3.0 min)
â„¹ Format: mp3
â„¹ Size: 2.45 MB
â„¹ Estimated cost: $0.0108
â„¹ Starting transcription...

============================================================
Transcription Result
============================================================

âœ“ Used cached transcription
Language: en
Backend: openai
Duration: 180.5s

Transcript:
[Transcription text here...]

âœ“ Transcript saved to: ./data/output/meeting_transcript.txt
```

### Example 2: Long Meeting (Chunked)

```bash
$ python summarize.py transcribe long_meeting.mp3 --chunked

âš  Audio is longer than 10 minutes, using chunked transcription
â„¹ Processed 6 chunks

============================================================
Transcription Result
============================================================

Language: en
Backend: openai
Duration: 3605.2s (60.1 min)

[Full transcript merged from chunks...]
```

### Example 3: Cache Statistics

```bash
$ python summarize.py cache-stats

============================================================
Cache Statistics
============================================================

Transcription Cache:
  Hits: 12
  Misses: 5
  Hit Rate: 70.59%
  Total Requests: 17

Summary Cache:
  Hits: 0
  Misses: 0
  Hit Rate: 0.00%
  Total Requests: 0

Estimated Cost Saved: $1.23

Cache Directory: ./data/cache
  Transcriptions: 12 files, 1.45 MB
  Summaries: 0 files, 0.00 MB
```

## Performance

### Benchmarks

| Audio Duration | Backend | Processing Time | Cost |
|----------------|---------|-----------------|------|
| 5 minutes | OpenAI Whisper | ~15 seconds | $0.03 |
| 30 minutes | OpenAI Whisper | ~45 seconds | $0.18 |
| 60 minutes | OpenAI Whisper (chunked) | ~2 minutes | $0.36 |
| 5 minutes | Whisper.cpp (local) | ~3 minutes | $0.00 |

### Cost Analysis

**Without Caching:**
- 30-minute daily standup: $0.18 per meeting
- 20 workdays/month: $3.60/month

**With Caching (70% hit rate):**
- Same scenario: $1.08/month
- **Savings: $2.52/month (70%)**

## Supported Audio Formats

| Format | Extension | Notes |
|--------|-----------|-------|
| MP3 | .mp3 | Most common, good compression |
| WAV | .wav | Uncompressed, large files |
| WebM | .webm | Web recording standard |
| M4A | .m4a | Apple/AAC format |
| OGG | .ogg | Open format, good quality |
| FLAC | .flac | Lossless compression |

## Troubleshooting

### Issue: "Audio validation failed: File size exceeds maximum"

**Solution:** Increase `MAX_AUDIO_SIZE_MB` in `.env` or compress audio:

```bash
# Using ffmpeg to compress
ffmpeg -i large_meeting.wav -b:a 64k meeting.mp3
```

### Issue: "OpenAI API error: Invalid API key"

**Solution:** Check your `.env` file:

```bash
# Make sure your API key is set correctly
OPENAI_API_KEY=sk-...your-key-here...
```

### Issue: "Module 'pydub' not found"

**Solution:** Install dependencies:

```bash
pip install -r requirements.txt
```

### Issue: "ffmpeg not found"

**Solution:** Install ffmpeg:

```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg
```

### Issue: Transcription is slow for long audio

**Solution:** Use chunked processing:

```bash
python summarize.py transcribe long_meeting.mp3 --chunked
```

## Phase 2 Examples

### Example 1: Quick Meeting Summary

```bash
$ python summarize.py analyze standup.mp3 --level brief

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Meeting Summarizer - Phase 1        â•‘
â•‘   Audio Transcription with Caching    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â„¹ Initializing analysis pipeline...
â„¹ Validating audio file: standup.mp3
â„¹ Duration: 300.5s (5.0 min)
â„¹ Format: mp3
â„¹ Starting full meeting analysis...

============================================================
Analysis Complete
============================================================

Summary:
Daily standup covering sprint progress. Team completed 3 tickets,
blocked on API integration. Decision made to escalate blocker to
platform team. Next standup scheduled for tomorrow 9 AM.

Key Topics:
  1. Sprint Progress Review
  2. API Integration Blocker
  3. Platform Team Escalation

Action Items: 2
  â€¢ Escalate API integration issue to platform team
    Assignee: Alice
  â€¢ Update ticket status in Jira
    Assignee: Bob

Statistics:
  Processing Time: 45.2s
  Total Cost: $0.0234
  Cache Hits: 0

âœ“ Report saved to: ./data/output/standup_analysis.markdown
```

### Example 2: Detailed Analysis with All Features

```bash
$ python summarize.py analyze quarterly_review.mp3 --level detailed

============================================================
Analysis Complete
============================================================

Summary:
[Comprehensive 3-paragraph summary with context, decisions,
and action items integrated throughout...]

Key Topics:
  1. Q4 Revenue Performance
  2. Customer Retention Metrics
  3. Product Roadmap 2025
  4. Team Expansion Plans
  5. Budget Allocation

Action Items: 8
  â€¢ Finalize Q1 hiring plan
    Assignee: HR Team
  â€¢ Review product roadmap with stakeholders
    Assignee: Product Lead
  ... and 6 more

Decisions Made: 4
  1. Approved 15% budget increase for engineering
  2. Moved product launch from Feb to March
  3. Approved 3 new engineering hires
  4. Decided to sunset legacy dashboard

Statistics:
  Processing Time: 120.8s
  Total Cost: $0.1245
  Cache Hits: 1

âœ“ Report saved to: ./data/output/quarterly_review_analysis.markdown
```

## Phase 3 Examples

### Example 1: Batch Processing Multiple Meetings

```bash
$ python summarize.py batch ./meetings --recursive --workers 4

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Meeting Summarizer - Phase 1        â•‘
â•‘   Audio Transcription with Caching    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â„¹ Initializing batch processor...
â„¹ Searching for audio files in: ./meetings
â„¹ Found 12 audio file(s)

â„¹ Processing 12 files with 4 workers...

Processing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [03:45<00:00,  3.21s/file]

============================================================
Batch Processing Complete
============================================================

Summary:
  Total Files: 12
  Successful: 11
  Failed: 1
  Processing Time: 225.3s
  Total Cost: $1.2450

Errors:
  â€¢ corrupted_meeting.mp3: Audio validation failed: Invalid format

â„¹ Generating batch report...
âœ“ Batch report saved to: ./data/output/batch_report.md
```

### Example 2: Batch with Individual Reports

```bash
$ python summarize.py batch ./meetings --save-individual --level brief

# Processes all files and saves individual analysis reports
# Output:
#   - meeting1_analysis.markdown
#   - meeting2_analysis.markdown
#   - ...
#   - batch_report.md (summary of all)
```

### Example 3: Parallel Processing with Custom Workers

```bash
$ python summarize.py batch ./archive --workers 8 --format json

# Use 8 parallel workers for faster processing
# Output format: JSON for programmatic access
```

## Phase 4 Examples

### Example 1: Starting the Web Server

```bash
$ python server.py

INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)

# Open browser to http://localhost:8000
```

### Example 2: Using the Web Interface

1. **Upload File**: Drag and drop your meeting audio file or click "Select File"
2. **Configure Options**:
   - Summary Level: Brief / Standard / Detailed
   - Output Format: Markdown / JSON / HTML / TXT
   - Language: (optional) en, es, fr, etc.
   - Extract Actions: âœ“ Enable action item extraction
   - Extract Topics: âœ“ Enable key topic extraction
3. **Start Analysis**: Click "Start Analysis" button
4. **Watch Progress**: Real-time progress with stage indicators:
   - â³ Validation
   - â³ Transcription
   - â³ Summarization
   - â³ Action Extraction
   - â³ Report Generation
5. **Download Report**: Click "Download Report" when complete

### Example 3: API Usage

```bash
# Upload file
curl -X POST http://localhost:8000/api/upload \
  -F "file=@meeting.mp3"
# Returns: {"job_id": "abc-123", ...}

# Start analysis
curl -X POST "http://localhost:8000/api/analyze/abc-123?summary_level=standard"

# Check status
curl http://localhost:8000/api/jobs/abc-123

# Download report
curl http://localhost:8000/api/jobs/abc-123/download -o report.md
```

### Example 4: WebSocket Real-time Updates

```javascript
const ws = new WebSocket('ws://localhost:8000/ws/abc-123');

ws.onmessage = (event) => {
  const progress = JSON.parse(event.data);
  console.log(`Progress: ${progress.progress_percent}%`);
  console.log(`Stage: ${progress.current_stage}`);
};
```

## Phase 5 Examples

### Example 1: Processing Video Files

```bash
$ python summarize.py analyze meeting_recording.mp4

â„¹ Initializing services...
â„¹ Detected video file: meeting_recording.mp4
â„¹ Extracting audio from video...
â„¹ Audio extracted successfully: meeting_recording_audio.mp3 (15.42 MB)
â„¹ Duration: 1825.3s (30.4 min)
â„¹ Starting full meeting analysis...

============================================================
Analysis Complete
============================================================

Summary:
[Full analysis of extracted audio...]

âœ“ Report saved to: ./data/output/meeting_recording_analysis.markdown
```

**Supported video formats**: MP4, AVI, MOV, MKV, WebM, FLV, WMV, M4V, 3GP

### Example 2: Using Custom Summary Templates

```bash
$ python summarize.py analyze meeting.mp3 --template executive

# Uses executive template for C-level summaries:
# - Key highlights and strategic decisions
# - Top 5 critical action items
# - Impact analysis
```

**Available templates**:
- `executive`: High-level summary with critical actions
- `detailed`: Comprehensive analysis with full context
- `brief`: Quick summary with topics and actions
- `meeting_minutes`: Formal meeting minutes format
- `technical`: Technical format with JSON and metadata

### Example 3: Speaker Diarization

```bash
$ python summarize.py analyze meeting.mp3 --speakers

# Requires: HF_AUTH_TOKEN environment variable
# Requires: pip install pyannote.audio torch

â„¹ Speaker diarization enabled
â„¹ Diarization complete: found 3 speakers

============================================================
Speaker-Attributed Transcript
============================================================

SPEAKER_00:
  Good morning everyone. Let's start with the sprint review.

SPEAKER_01:
  Thanks. I completed the authentication feature yesterday.
  It's ready for code review.

SPEAKER_02:
  Great work! I'll review it this afternoon.

============================================================
Speaker Statistics
============================================================

SPEAKER_00: 45.2% (8.3 min, 12 segments)
SPEAKER_01: 32.1% (5.9 min, 8 segments)
SPEAKER_02: 22.7% (4.2 min, 6 segments)
```

### Example 4: Database-Persisted Jobs via Web UI

```bash
$ python server.py

# Server starts with SQLite database
# All jobs automatically persisted to ./data/database.db

# Upload and analyze via web UI
# Jobs persist across server restarts
# View historical analysis results
# Track processing statistics
```

**Database features**:
- Job history with timestamps
- Resume interrupted jobs
- Search by filename or date
- Export job data as JSON
- Automatic cleanup of old jobs

### Example 5: Creating Custom Templates

Create `templates/custom/standup.md`:

```jinja2
# Daily Standup - {{filename}}

**Date**: {{date}}
**Duration**: {{duration_minutes}} minutes

## What We Discussed
{{summary}}

## Action Items ({{action_items|length}})
{% for action in action_items %}
- [ ] {{action.description}} (@{{action.assignee}})
{% endfor %}

## Blockers
{% for decision in decisions %}
- {{decision.decision}}
{% endfor %}
```

Then use it:

```bash
$ python summarize.py analyze standup.mp3 --template standup
# Uses your custom template
```

## Project Structure

```
python-projects/09-meeting-summarizer/
â”œâ”€â”€ summarize.py                    # CLI entry point âœ…
â”œâ”€â”€ server.py                       # Web server âœ…
â”œâ”€â”€ requirements.txt                # Dependencies âœ…
â”œâ”€â”€ .env.example                    # Config template âœ…
â”œâ”€â”€ README.md                       # This file âœ…
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py                 âœ…
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py             âœ…
â”‚   â”‚   â”œâ”€â”€ audio_processor.py      # Audio operations âœ…
â”‚   â”‚   â”œâ”€â”€ transcription_service.py # Transcription âœ…
â”‚   â”‚   â”œâ”€â”€ cache_manager.py        # Caching âœ…
â”‚   â”‚   â”œâ”€â”€ llm_client.py           # Unified LLM interface âœ…
â”‚   â”‚   â”œâ”€â”€ summarizer.py           # AI summarization âœ…
â”‚   â”‚   â”œâ”€â”€ action_extractor.py     # Action item extraction âœ…
â”‚   â”‚   â””â”€â”€ meeting_analyzer.py     # Main orchestrator âœ…
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py             âœ…
â”‚       â”œâ”€â”€ batch_processor.py      # Batch processing âœ…
â”‚       â”œâ”€â”€ progress_tracker.py     # Progress tracking âœ…
â”‚       â”œâ”€â”€ database.py             # Database persistence âœ…
â”‚       â”œâ”€â”€ video_processor.py      # Video audio extraction âœ…
â”‚       â”œâ”€â”€ speaker_diarization.py  # Speaker identification âœ…
â”‚       â””â”€â”€ summary_templates.py    # Custom templates âœ…
â”œâ”€â”€ templates/                      # Web UI templates âœ…
â”‚   â””â”€â”€ index.html                  # Main interface âœ…
â”œâ”€â”€ static/                         # Frontend assets âœ…
â”‚   â”œâ”€â”€ app.js                      # JavaScript logic âœ…
â”‚   â””â”€â”€ styles.css                  # Styling âœ…
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”œâ”€â”€ transcriptions/         âœ…
â”‚   â”‚   â””â”€â”€ summaries/              âœ…
â”‚   â”œâ”€â”€ uploads/                    âœ…
â”‚   â””â”€â”€ output/                     âœ…
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py                 âœ…
    â”œâ”€â”€ fixtures/
    â”‚   â””â”€â”€ sample.py.backup        âœ…
    â””â”€â”€ test_*.py                   # Test suite ready
```

## Phase 2 Components

### LLM Client ([llm_client.py](src/core/llm_client.py))
Unified interface for multiple LLM providers:
- **OpenAI**: GPT-4, GPT-4o-mini
- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Haiku
- **Ollama**: Local models (llama3.2, phi3, qwen, gemma2)

Automatic cost estimation and token tracking for all providers.

### Summarizer ([summarizer.py](src/core/summarizer.py))
AI-powered summarization with map-reduce strategy:
- **Direct summarization**: For transcripts <4000 words
- **Map-reduce**: Splits long transcripts into chunks, summarizes each, then combines
- **Multi-level**: Brief (2-3 paragraphs), Standard (balanced), Detailed (comprehensive)
- **Topic extraction**: Identifies key discussion points

### Action Extractor ([action_extractor.py](src/core/action_extractor.py))
Extracts structured information from transcripts:
- **Action Items**: Tasks with assignees, due dates, priorities
- **Decisions**: What was decided with context and impact
- **Follow-ups**: Items requiring future attention
- **JSON output**: Structured data for integration
- **Validation**: Checks completeness of extracted items

### Meeting Analyzer ([meeting_analyzer.py](src/core/meeting_analyzer.py))
Main orchestrator managing the full pipeline:
- Coordinates transcription â†’ summarization â†’ action extraction
- Manages two-level caching at each stage
- Generates reports in multiple formats
- Tracks cost and performance statistics


## Phase 3 Components

### Batch Processor ([batch_processor.py](src/utils/batch_processor.py))
Parallel processing for multiple audio files:
- **Parallel execution**: ProcessPoolExecutor with configurable workers
- **Progress tracking**: Real-time tqdm progress bars
- **Error handling**: Continue on error, collect failed files
- **Batch reports**: Markdown summary with statistics
- **Auto-discovery**: Find audio files recursively in directories

### Progress Tracker ([progress_tracker.py](src/utils/progress_tracker.py))
State management and resume capability:
- **Real-time tracking**: Progress updates with callbacks
- **State persistence**: JSON-based checkpoint system
- **Resume support**: Load previous state and continue
- **Cancellation**: Interrupt processing gracefully
- **Stage tracking**: Monitor pipeline stages (validation â†’ transcription â†’ summarization â†’ actions)

## Phase 4 Components

### FastAPI Server ([server.py](server.py))
Production-ready web server with REST API:
- **REST API**: Upload, analyze, download endpoints
- **WebSocket**: Real-time progress updates for active jobs
- **Background tasks**: Async processing with FastAPI BackgroundTasks
- **Job management**: Track, list, and delete analysis jobs
- **CORS support**: Configurable origins for API access

### Web UI ([templates/index.html](templates/index.html))
Modern single-page application:
- **Drag-and-drop upload**: Intuitive file selection
- **Analysis options**: Configure summary level, format, language
- **Real-time progress**: Visual progress bar with stage indicators
- **Results display**: Summary preview, topics, action items
- **Download reports**: Direct browser download
- **Responsive design**: Works on mobile and desktop

### Frontend JavaScript ([static/app.js](static/app.js))
Interactive client-side logic:
- **File validation**: Check format and size before upload
- **WebSocket client**: Connect for real-time updates
- **Progress visualization**: Update UI based on server messages
- **API integration**: RESTful calls to backend
- **Error handling**: User-friendly error messages

### CSS Styling ([static/styles.css](static/styles.css))
Professional UI design:
- **Modern aesthetics**: Clean, gradient-based design
- **Progress indicators**: Animated progress bars and stage icons
- **Responsive layout**: Grid-based, mobile-friendly
- **Status colors**: Visual feedback for success/error/in-progress
- **Accessibility**: High contrast, readable fonts

## Phase 5 Components

### Database Manager ([database.py](src/utils/database.py))
SQLAlchemy-based persistence layer:
- **Job model**: Complete job state tracking (20+ columns)
- **SQLite default**: Zero-config local database
- **PostgreSQL support**: Production-ready with connection pooling
- **CRUD operations**: Create, read, update, delete jobs
- **Statistics tracking**: Cost, processing time, cache hits
- **Auto-migration**: Schema creation on first run

**Job attributes tracked**:
```python
id, filename, file_path, status, summary_level, language,
progress_percent, current_stage, transcript_text, summary_text,
action_items_json, topics_json, decisions_json, error_message,
started_at, completed_at, processing_time_seconds, total_cost_usd,
cache_hits, output_file_path
```

### Video Processor ([video_processor.py](src/utils/video_processor.py))
FFmpeg-based video audio extraction:
- **Format support**: MP4, AVI, MOV, MKV, WebM, FLV, WMV, M4V, 3GP
- **Audio extraction**: Converts video to MP3/WAV for transcription
- **Metadata extraction**: Duration, codecs, resolution via ffprobe
- **Quality control**: Configurable bitrate, sample rate
- **Cleanup**: Automatic temporary file management
- **Error handling**: Graceful fallback with detailed error messages

**Usage**:
```python
processor = VideoProcessor()
if processor.is_video_file('meeting.mp4'):
    audio_path = processor.extract_audio('meeting.mp4')
    # Returns: 'data/temp/meeting_audio.mp3'
```

### Speaker Diarization ([speaker_diarization.py](src/utils/speaker_diarization.py))
Pyannote.audio-based speaker identification:
- **Speaker detection**: Automatically identify multiple speakers
- **Timestamp segmentation**: Who spoke when
- **Speaker statistics**: Talk time percentages, segment counts
- **Transcript attribution**: Assign text to speakers
- **Optional dependency**: Graceful degradation if not installed
- **Hugging Face auth**: Requires HF_AUTH_TOKEN for model access

**Requirements**:
```bash
pip install pyannote.audio torch
export HF_AUTH_TOKEN=your_huggingface_token
```

**Output format**:
```python
[
    {
        "start": 0.0,
        "end": 5.2,
        "speaker": "SPEAKER_00",
        "duration": 5.2
    },
    ...
]
```

### Summary Template Manager ([summary_templates.py](src/utils/summary_templates.py))
Jinja2-based report generation:
- **5 default templates**: executive, detailed, brief, meeting_minutes, technical
- **Custom templates**: Load from `templates/custom/` directory
- **Template context**: Full analysis data with 20+ variables
- **Fallback rendering**: Graceful degradation on template errors
- **Template discovery**: Auto-detect custom templates

**Template variables**:
```jinja2
{{ filename }}, {{ date }}, {{ duration_minutes }}, {{ summary }},
{{ topics }}, {{ action_items }}, {{ decisions }}, {{ processing_time }},
{{ cost }}, {{ attendees }}, {{ llm_provider }}, {{ cache_hits }}
```

**Creating custom templates**:
1. Create `templates/custom/mytemplate.md`
2. Use Jinja2 syntax with available variables
3. Use: `--template mytemplate`

## Coming in Phase 6 (Future)

- ğŸ”„ Calendar/Slack integration for automated processing
- ğŸ”„ Multi-language transcription UI with language detection
- ğŸ”„ User authentication and multi-tenant support
- ğŸ”„ Real-time live meeting transcription (streaming)
- ğŸ”„ Advanced speaker recognition with voice profiles
- ğŸ”„ Sentiment analysis and tone detection
- ğŸ”„ Meeting insights dashboard with analytics
- ğŸ”„ Export to calendar invites with action items

## License

Part of the AI Experiments Hub repository.

## Contributing

**Status**: Phases 1-5 Complete âœ…

Full-featured meeting summarizer with:
- âœ… CLI and web interface
- âœ… Multi-backend transcription (cloud + local)
- âœ… AI-powered summarization and action extraction
- âœ… Batch processing with parallel execution
- âœ… Database persistence and job history
- âœ… Video file support with audio extraction
- âœ… Speaker diarization (optional)
- âœ… Custom summary templates

**Future development** (Phase 6): Calendar integration, live transcription, sentiment analysis, and advanced analytics.
