# LLM Configuration
LLM_PROVIDER=ollama           # ollama, anthropic, openai
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
ANTHROPIC_API_KEY=
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4

# Cache Settings
ENABLE_CACHE=true
CACHE_DIR=./data/cache
CACHE_EXPIRY_DAYS=7

# Output Settings
DEFAULT_OUTPUT_DIR=./data/output
DEFAULT_FORMAT=markdown

# Web Server (for serve command)
WEB_HOST=127.0.0.1
WEB_PORT=8000

# Parser Settings
NODEJS_PATH=node              # Path to Node.js for JS parsing
